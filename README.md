# PyTorch Scratch Implementations

This repository contains PyTorch implementations built from scratch for various NLP tasks and neural network architectures.

## Contents

### Tokenization & Text Processing
- **a1_p1_Bhuma_116036784.py** - Word RegEx tokenizer and Spaceless BytePair tokenizer implementations for text processing
- **a1_p2_Bhuma_116036784.py** - Part-of-Speech (POS) tagging using neural networks with custom word embeddings

### Language Modeling
- **a2_p1_Bhuma_116036784.py** - Smoothed Trigram language model with GPT-2 tokenization for song lyrics generation
- **a2_p2_Bhuma_116036784.py** - Neural language model built from scratch with custom transformer architecture for text generation

### Advanced NLP Tasks
- **a3_p1_Bhuma_116036784.py** - Sequence-to-sequence models and attention mechanisms
- **a3_p2_Bhuma_116036784.py** - Advanced transformer implementations with self-attention layers
- **a3_p3_Bhuma_116036784.py** - Fine-tuned language models for downstream NLP tasks

## Technologies

- Python
- PyTorch
- Transformers (HuggingFace)
- NumPy
- scikit-learn

## Description

These implementations demonstrate building neural network components and NLP models from scratch using PyTorch, focusing on understanding the underlying mechanics of tokenization, language modeling, and deep learning architectures for natural language processing.
